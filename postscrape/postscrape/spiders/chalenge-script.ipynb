{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"################################## My spider ##########################\")\n",
    "import scrapy\n",
    "import sys\n",
    "import html2text \n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = 'testing'\n",
    "    #allowed_domains = ['theguardian.com']\n",
    "\n",
    "    catg = ''\n",
    "\n",
    "    def __init__(self, category=None, *args, **kwargs):\n",
    "        super(MySpider, self).__init__(*args, **kwargs)\n",
    "        self.start_urls = ['https://www.theguardian.com/%s?page=1' % category]\n",
    "        global catg \n",
    "        catg = category\n",
    "        \n",
    "    #categories = [\"world\",\"environment\",\"science\",\"cities\",\"global-development\",\"football\",\"technology\",\"business\"]\n",
    "    #start_urls = [\n",
    "    #                'https://www.theguardian.com/science?page=1'\n",
    "    #            ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        #Use htmt2text to get the plain text\n",
    "        converter = html2text.HTML2Text()\n",
    "        converter.ignore_links = True\n",
    "        \n",
    "        if  response.css('h1::text').get() != ' ':\n",
    "                #Get informations relevant to the news story\n",
    "                h_title = response.css('h1').get()\n",
    "                h_date = response.css('time::text').get()\n",
    "                h_body = response.css('div.content__article-body p').extract()\n",
    "\n",
    "                #Return these informations\n",
    "                yield {\n",
    "                'URL' : \"https://www.theguardian.com\"+response.css('html::attr(data-page-path)').get(),\n",
    "                'Title' : ((converter.handle(str(h_title)).strip()).replace(\"\\n\\n\", '')).replace(\"\\n\", ' '),\n",
    "                'Date' : h_date.strip(),\n",
    "                'Author(s)' : response.css('a.tone-colour span::text').getall(),\n",
    "                'Content' : ((str((converter.handle(str(h_body))).strip())).replace(\"\\n\\n\",'')).replace(\"\\n\",' ')\n",
    "                            \n",
    "                }         \n",
    "        #response.xpath('//a[@class=\"u-faux-block-link__overlay js-headline-text\"]/@href').extract() or response.css('a.u-faux-block-link__overlay.js-headline-text::attr(href)').getall()\n",
    "        for article_url in response.css('section.fc-container.fc-container--tag a.u-faux-block-link__overlay.js-headline-text::attr(href)').getall():\n",
    "            yield scrapy.Request(response.urljoin(article_url), self.parse)\n",
    "        \n",
    "        \n",
    "        next_page = response.css('a.button.button--small.button--tertiary.pagination__action--static[rel=\"next\"]::attr(href)').get()\n",
    "        if next_page == ('https://www.theguardian.com/%s?page=101' % catg):\n",
    "            sys.exit(\"Limit reached !\")\n",
    "        yield scrapy.Request(response.urljoin(next_page), self.parse)\n",
    "             \n",
    "#testing1.json: For performance reasons, document symbols have been limited to 5000 items.\n",
    "#Use setting 'json.maxItemsComputed' to configure the limit.\n",
    "\n",
    "#science:\n",
    "#Start at 15:07:02\n",
    "#Finished at 15:09:43\n",
    "\n",
    "#world:\n",
    "#Start at 15:07:02\n",
    "#Finished at 15:09:43\n",
    "\n",
    "#environment:\n",
    "#Start at 15:16:02\n",
    "#Finished at 15:09:43\n",
    "\n",
    "\n",
    "#client = pymongo.MongoClient(\"mongodb+srv://CHEA:<password>@mycluster-uykvf.azure.mongodb.net/test?retryWrites=true&w=majority\")\n",
    "#db = client.test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapy crawl testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
